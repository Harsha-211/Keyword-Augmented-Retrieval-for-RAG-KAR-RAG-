{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55ef39ab-97a7-4518-88b7-8ba7e0338d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import faiss\n",
    "import ollama\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import T5Tokenizer, DataCollatorForSeq2Seq\n",
    "from transformers import T5ForConditionalGeneration, Seq2SeqTrainingArguments,Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58b87ee9-ee7f-4509-903a-6c56bf8d3ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(text):\n",
    "    html = BeautifulSoup(text)\n",
    "    return html.text\n",
    "def remove_punctuations(text):\n",
    "    return re.sub('[^a-zA-Z]',' ',text)\n",
    "def remove_spaces(text):\n",
    "    return re.sub(r'\\s+',' ',text)\n",
    "def remove_singles(text):\n",
    "    return re.sub(r'\\b[a-zA-Z]\\b','' ,text)\n",
    "def clean_text(text):\n",
    "    text = remove_tags(text)\n",
    "    text = remove_punctuations(text)\n",
    "    text = remove_singles(text)\n",
    "    text = remove_spaces(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9410780-0b4b-4fa4-94ba-902425c99e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D:/Pythonn/RAG/Improving RAG/Hotpot/hotpot_train_v1.1.json\", 'r' , encoding = 'utf-8') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b597b487-8f02-4478-9e36-6bc62c6c0d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for item in data:\n",
    "    question = item['question']\n",
    "    answer = item['answer']\n",
    "    level = item['level']\n",
    "    q_type = item['type']\n",
    "    _id = item['_id']\n",
    "    context_texts = item['context']\n",
    "    data_list.append({\n",
    "        'question': question,\n",
    "        'answer': answer,\n",
    "        'level': level,\n",
    "        'type': q_type,\n",
    "        '_id': _id,\n",
    "        'context': context_texts\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c44954c8-6f68-45f2-928a-5a04e02544ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>level</th>\n",
       "      <th>type</th>\n",
       "      <th>_id</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which magazine was started first Arthur's Maga...</td>\n",
       "      <td>Arthur's Magazine</td>\n",
       "      <td>medium</td>\n",
       "      <td>comparison</td>\n",
       "      <td>5a7a06935542990198eaf050</td>\n",
       "      <td>[[Radio City (Indian radio station), [Radio Ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Oberoi family is part of a hotel company t...</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>medium</td>\n",
       "      <td>bridge</td>\n",
       "      <td>5a879ab05542996e4f30887e</td>\n",
       "      <td>[[Ritz-Carlton Jakarta, [The Ritz-Carlton Jaka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Musician and satirist Allie Goertz wrote a son...</td>\n",
       "      <td>President Richard Nixon</td>\n",
       "      <td>hard</td>\n",
       "      <td>bridge</td>\n",
       "      <td>5a8d7341554299441c6b9fe5</td>\n",
       "      <td>[[Lisa Simpson, [Lisa Marie Simpson is a ficti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What nationality was James Henry Miller's wife?</td>\n",
       "      <td>American</td>\n",
       "      <td>medium</td>\n",
       "      <td>bridge</td>\n",
       "      <td>5a82171f5542990a1d231f4a</td>\n",
       "      <td>[[Moloch: or, This Gentile World, [Moloch: or,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cadmium Chloride is slightly soluble in this c...</td>\n",
       "      <td>alcohol</td>\n",
       "      <td>medium</td>\n",
       "      <td>bridge</td>\n",
       "      <td>5a84dd955542997b5ce3ff79</td>\n",
       "      <td>[[Cadmium chloride, [Cadmium chloride is a whi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question                   answer  \\\n",
       "0  Which magazine was started first Arthur's Maga...        Arthur's Magazine   \n",
       "1  The Oberoi family is part of a hotel company t...                    Delhi   \n",
       "2  Musician and satirist Allie Goertz wrote a son...  President Richard Nixon   \n",
       "3    What nationality was James Henry Miller's wife?                 American   \n",
       "4  Cadmium Chloride is slightly soluble in this c...                  alcohol   \n",
       "\n",
       "    level        type                       _id  \\\n",
       "0  medium  comparison  5a7a06935542990198eaf050   \n",
       "1  medium      bridge  5a879ab05542996e4f30887e   \n",
       "2    hard      bridge  5a8d7341554299441c6b9fe5   \n",
       "3  medium      bridge  5a82171f5542990a1d231f4a   \n",
       "4  medium      bridge  5a84dd955542997b5ce3ff79   \n",
       "\n",
       "                                             context  \n",
       "0  [[Radio City (Indian radio station), [Radio Ci...  \n",
       "1  [[Ritz-Carlton Jakarta, [The Ritz-Carlton Jaka...  \n",
       "2  [[Lisa Simpson, [Lisa Marie Simpson is a ficti...  \n",
       "3  [[Moloch: or, This Gentile World, [Moloch: or,...  \n",
       "4  [[Cadmium chloride, [Cadmium chloride is a whi...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9682b050-27af-4bef-9fc5-e2c343fc96c9",
   "metadata": {},
   "source": [
    "# Initiating DB and required items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e846fb70-aebb-4611-8193-0a61e8e524e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 384\n",
    "index = faiss.IndexFlatIP(dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e1c5251-5805-44ad-b509-1aff186adb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_embeddings(embeddings: np.ndarray)->np.ndarray:\n",
    "    norm = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "    return embeddings/norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf9f8727-5d6d-4264-bbec-6987984c3ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-miniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d47e6e-b174-4764-a1ab-2be414db8f1b",
   "metadata": {},
   "source": [
    "# Inserting Data into DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ced0103e-2371-4b1c-bda6-c900fb9e8c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df['context'].to_list()\n",
    "data = data[:100]\n",
    "data = [item for sublist in data for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36791e4c-dee1-46d3-9825-110559a211d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    title = data[i][0]\n",
    "    content = \" \".join(data[i][1])\n",
    "    text = f\"{title}: {content}\"\n",
    "    data[i] = clean_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a237c505-bb47-495a-9e3a-f7b508849098",
   "metadata": {},
   "source": [
    "## key word extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e01bae7-5362-4b82-b5b2-e8d76f5d4073",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_checkpoint = \"D:/Pythonn/Optimizing VectorDB/results/checkpoint-852\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f878bef3-c547-4608-8fe1-e8ef2d30911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_model = T5ForConditionalGeneration.from_pretrained(last_checkpoint)\n",
    "tokenizer = T5Tokenizer.from_pretrained(last_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e73bd30-8f0b-48a1-a629-1457ebef25a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(paragraph):\n",
    "    inputs = f\"Etract Keywords from the Paragraph:\\n {paragraph}\"\n",
    "    inputs = tokenizer(inputs, return_tensors=\"pt\")\n",
    "    outputs = finetuned_model.generate(**inputs)\n",
    "    answer = tokenizer.decode(outputs[0])\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8eb8b73f-3641-474a-af6f-87939b6b7b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords =  []\n",
    "for i in range(len(data)):\n",
    "    keywords.append(extract_keywords(data[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d68728b-b085-4ee0-8e31-53f6b67581dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad>Radio City Indian radio station Radio City India first private FM radio station started July broadcasts earlier most cities'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03da9cbd-5c7b-41b5-b5c9-b49b5dd0f722",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(keywords) == len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "135bfcec-d3bc-4c4c-9539-0370c4c7bb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_df = pd.DataFrame(keywords, columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "570ba9ec-256d-4061-a188-f56b1543417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_df.to_csv('sum_hotpot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6e8af6a-9af3-4cb4-85ad-330f48233639",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_df = pd.read_csv('sum_hotpot.csv')\n",
    "sum_df['text'] = sum_df['text'].apply(func=clean_text)\n",
    "sumarize = sum_df['text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bce2304-585a-4a59-8057-7172fc5b3681",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode(sumarize, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81a61a51-da3e-410a-bfc3-b306ba1f637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_metadata = {}\n",
    "for i, (emb, text) in enumerate(zip(embeddings, data)):\n",
    "    emb_cpu = emb.cpu().numpy()   # move to CPU and convert to numpy\n",
    "    emb_cpu = emb_cpu.astype('float32')  # ensure float32 dtype (Faiss needs this)\n",
    "    index.add(np.expand_dims(emb_cpu, axis=0))\n",
    "    id_to_metadata[i] = {\"id\": f\"chunk_{i}\", \"text\": text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d732613d-ea6e-44c6-86f5-f3fca3d17237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_DB(query):\n",
    "    # 1. Encode and normalize query embedding\n",
    "    query_embedding = model.encode([query], convert_to_numpy=True)\n",
    "    query_embedding = query_embedding.astype('float32')\n",
    "    query_embedding = normalize_embeddings(query_embedding)\n",
    "\n",
    "    # 2. Search Faiss index\n",
    "    top_k = 10\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "\n",
    "    results = []\n",
    "    for dist, idx in zip(distances[0], indices[0]):\n",
    "        metadata = id_to_metadata.get(idx, {})\n",
    "        results.append({\n",
    "            'id': metadata.get('id'),\n",
    "            'text': metadata.get('text'),\n",
    "            'score': float(dist)\n",
    "        })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc4dc9f0-5227-4295-a498-e022a129abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(query):\n",
    "    context = search_DB(query)\n",
    "    context_text = \"\\n\".join([item['text'] for item in context])\n",
    "    prompt = f'Based on the given context:\\n\"\"\"\\n{context_text}\\n\"\"\"\\nAnswer the question: \"{query}\"'\n",
    "    stream = ollama.chat(\n",
    "        model='llama3.2:3b',\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "        stream=False\n",
    "    )\n",
    "    return stream['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "005d68d1-2e3f-484e-b6c4-953eca8b5b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, First for Women was started first. The text states that First for Women was started in 1930 (incomplete sentence). However I can tell you it was first published in 1930 while Arthur's magazine is stated to be an American literary periodical from the th century"
     ]
    }
   ],
   "source": [
    "for token in answer(df['question'][0]):\n",
    "    print(token, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df067a4-8dab-42ce-94ef-989a7e0305b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
